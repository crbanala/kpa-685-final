# -*- coding: utf-8 -*-
"""sentiment_analysis_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BhHUpo9cwgtfDpXoMTFBM9SzgrugI-ix
"""

from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

FOLDERNAME = 'nlp_data'
assert FOLDERNAME is not None, "[!] Enter the foldername."

#Now that we've mounted your Drive, this ensures that
# the Python interpreter of the Colab VM can load
# python files from within it.
import sys
sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))

# %cd /content/drive/My\ Drive/$FOLDERNAME/

import json
import nltk
nltk.download('punkt')

with open('/content/drive/My Drive/nlp_data/review_dataset/train.json') as json_file:
    train = json.load(json_file)

rev_list = []
rating_list = []
review_count = 0
for business in train.keys():
  reviews_list = train[business]['review_list'].copy()

  for review in reviews_list:
    text = review['text']
    rating = review['rating']
    text = text[:-1] if text[-1] == '.' else text
    review_count = len(text.split('.'))
    if review_count < 4 and len(nltk.word_tokenize(text)) < 65:
      
      if rating in [1.0, 2.0]:
        rev_list.append(text)
        rating_list.append(0)
      elif rating == 3.0:
        rev_list.append(text)
        rating_list.append(1)
      elif rating in [4.0, 5.0]:
        rev_list.append(text)
        rating_list.append(2)
      else:
        continue

len(rev_list)

set(rating_list)

sent_train= [rev_list[:int(0.9*len(rev_list))], rating_list[:int(0.9*len(rating_list))]]

len(sent_train[0])

sent_test= [rev_list[int(0.9*len(rev_list)):], rating_list[int(0.9*len(rating_list)):]]

len(sent_test[0])

with open('/content/drive/My Drive/nlp_data/review_dataset/sent_train.json', 'w', encoding ='utf8') as json_file:
    json.dump(sent_train, json_file)

with open('/content/drive/My Drive/nlp_data/review_dataset/sent_test.json', 'w', encoding ='utf8') as json_file:
    json.dump(sent_test, json_file)
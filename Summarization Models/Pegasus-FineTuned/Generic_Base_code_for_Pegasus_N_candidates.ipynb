{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tm8iWSEpNBNM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import random as rn\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,average_precision_score, precision_score,precision_recall_curve\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm import trange\n",
        "import warnings\n",
        "import pickle\n",
        "import nltk\n",
        "import math\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "#import neptune.new as neptune                          \n",
        "from torch.utils.data import (DataLoader, RandomSampler, WeightedRandomSampler, SequentialSampler, TensorDataset, Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1dUVMNkNJA5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760fcb07-fb71-42fd-e98e-53d7defea853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 92 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 122 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 153 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 163 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 170 kB 10.3 MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 298 kB 8.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 243 kB 62.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 684 kB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 67.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 160 kB 64.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 192 kB 76.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 69.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 8.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 72.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 49.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 28.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 8.7 MB/s \n",
            "\u001b[?25h  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji -q\n",
        "!pip install datasets -q\n",
        "!pip install rouge_score -q\n",
        "\n",
        "\n",
        "!pip install transformers -q\n",
        "!pip install sentencepiece -q\n",
        "!pip install pandarallel -q\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup,PegasusConfig, PegasusTokenizer, PegasusForConditionalGeneration\n",
        "from transformers import AutoTokenizer, AutoModel, set_seed, TrainingArguments, Trainer\n",
        "from transformers import default_data_collator, AdamW, get_linear_schedule_with_warmup, Seq2SeqTrainer, Seq2SeqTrainingArguments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpHO-ZWoOT3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b204909-ec4b-4c22-916a-62afed13c748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-UKxu9nNLO-"
      },
      "outputs": [],
      "source": [
        "model_name = 'google/pegasus-xsum'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_path = '/content/drive/MyDrive/EMNLP_folder_4/headline_model/checkpoint-4518'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_path)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_path).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKhJAeB5OJdT",
        "outputId": "4356a8db-1cd5-471f-bc21-b133c7827ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It is preferable to spend the money elsewhere']\n"
          ]
        }
      ],
      "source": [
        "src_text = [\"\"\"Boo. :(This is the best place at PDX to get breakfast.\"\"\"]\n",
        "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
        "translated = model.generate(**batch)\n",
        "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "print(tgt_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3AGjoGxP6Wf"
      },
      "outputs": [],
      "source": [
        "# reviews_path = '/content/drive/MyDrive/gen_datasets/res_reviews_final.json'\n",
        "reviews_path = '/content/drive/MyDrive/restaurant_reviews/res_reviews_final.json'\n",
        "import json\n",
        "f = open(reviews_path)\n",
        "data = json.load(f)\n",
        "data = json.loads(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Tr33X10TZUm"
      },
      "outputs": [],
      "source": [
        "x = {}\n",
        "for key_ in data.keys():\n",
        "  for a in data[key_]['review_list']:\n",
        "    if(a['rating']!=None):\n",
        "      x[a['text']] = a['rating']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "od = collections.OrderedDict(sorted(x.items()))"
      ],
      "metadata": {
        "id": "nBibdeVom0mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zoSwDQuTxsi"
      },
      "outputs": [],
      "source": [
        "reviews = []\n",
        "for j in sorted.items():\n",
        "  reviews.append(j[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7sTTKSAU0M2",
        "outputId": "e1c69b83-96cb-4ae7-8d5a-a202a0498b2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ['The food is not good enough']\n",
            "2 ['The food is good/healthy']\n",
            "4 ['Coffee is expensive']\n",
            "6 ['The food is unhealthy/unhealthy']\n",
            "8 ['There are issues more important to fund than food']\n",
            "10 ['There are issues more important to fund than food']\n",
            "12 ['Parents should be permitted to choose the education of their children']\n",
            "14 ['A pre-made sandwich is unhealthy/unnatural']\n",
            "16 ['People should choose for themselves whether or not to eat meat']\n",
            "18 ['The Celiac Disease is a big concern for those who are affected']\n",
            "20 ['Alcohol and tobacco are more harmful drugs yet remain legal']\n",
            "22 ['It is preferable to spend the money elsewhere']\n",
            "24 ['Alcohol and tobacco are more harmful drugs yet remain legal']\n",
            "26 ['The food is good']\n",
            "28 ['There are issues more important to fund than food/staff shortages.']\n",
            "30 ['The airport is a good place to eat/drink/shop']\n",
            "32 ['The food is good']\n",
            "34 ['The bakery is a good choice for a quick snack/snack']\n",
            "36 ['The airport is a good business location']\n",
            "38 ['The food is good/healthy']\n",
            "40 ['The food is good/healthy']\n",
            "42 ['The food is delicious']\n",
            "44 ['The airport is a good place to eat/drink/shop']\n",
            "46 ['People should choose for themselves whether or not to go to coffee shops']\n",
            "48 ['There are no fast food outlets in the main terminal']\n",
            "50 ['The Flying Elephant is a symbol of freedom/independence']\n",
            "52 ['Child performers should not be banned as long as there is supervision/regulation']\n",
            "54 ['The food is better than the alternatives']\n",
            "56 ['The food is good/healthy']\n",
            "58 ['It is preferable to spend the money elsewhere']\n",
            "60 ['If you want to eat healthy, go to a restaurant that serves healthy food']\n",
            "62 ['A la carte is a good option for catering/eating in-transit']\n",
            "64 ['The airport is a good place to eat/drink/jog/Discuss/educate']\n",
            "66 ['The food is delicious']\n",
            "68 ['The food is good']\n",
            "70 ['There are so many options for catering for events/gigs that we cannot choose which ones to attend']\n",
            "72 ['The food is good, the service is good, the atmosphere is good']\n",
            "74 ['There are issues more important to fund than food']\n",
            "76 ['The food is excellent']\n",
            "78 ['The food is delicious']\n",
            "80 ['It is preferable to spend the money elsewhere']\n",
            "82 ['It is preferable to spend the money elsewhere']\n",
            "84 ['The food is good/healthy']\n",
            "86 ['The food is delicious']\n",
            "88 ['The food is amazing']\n",
            "90 ['The Elephant is a symbol of freedom/liberties']\n",
            "92 ['The food is good']\n",
            "94 ['The Guantanamo bay detention camp is better for prisoners than the alternatives']\n",
            "96 ['A happy hour is a good idea']\n",
            "98 ['The airport is a good place to eat/drink/shop/educate/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/connect/']\n",
            "100 ['The airport is a good place to eat/drink/smooze']\n",
            "102 ['The food is delicious']\n",
            "104 ['A selection of the best local food/drinks is available in the capital city']\n",
            "106 ['The Soup Kitchen is a good choice for a quick lunch/dinner break']\n",
            "108 ['People who are ill do not have clear judgement and are in need of help']\n",
            "110 ['There are so many options for catering for events/gigs that it is difficult to know which ones to choose']\n",
            "112 ['The food is good/healthy']\n",
            "114 ['The broth is rich in nutrients']\n",
            "116 ['Food is important to the body']\n",
            "118 ['The food at Flying Elephants is delicious']\n",
            "120 ['The food is delicious']\n",
            "122 ['There are issues more important to fund than food, and the government should intervene']\n",
            "124 ['The Flying Elephants are a symbol of freedom/liberties']\n",
            "126 ['People should choose for themselves whether or not to eat meat']\n",
            "128 ['Child performers should not be banned as long as there is supervision/regulation']\n"
          ]
        }
      ],
      "source": [
        "num_kp = int(len(reviews)/50)\n",
        "input = []\n",
        "for i in range(len(reviews)):\n",
        "  if(i%num_kp==0):\n",
        "    input.append(reviews[i])\n",
        "    src_text = ''.join(input)\n",
        "    batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
        "    translated = model.generate(**batch)\n",
        "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "    print(i,tgt_text)\n",
        "    input = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4CWt7wMXfox"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Generic Base code for Pegasus_N_candidates.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}